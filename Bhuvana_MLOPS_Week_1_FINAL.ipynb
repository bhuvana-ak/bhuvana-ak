{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhuvana-ak/bhuvana-ak/blob/main/Bhuvana_MLOPS_Week_1_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 1 Project: Sentiment Analysis Project for Lamada E-commerce Platform\n",
        "Welcome to the Week 1 Project! In this project you will be taking on the role as an MLOps Engineer working on a new greenfield project over at Lamada a leading E-commerce Giant.\n",
        "\n",
        "![Lamada](https://drive.google.com/uc?id=17r13P5Wy9DtjmLEaiaXf3DUVViUXmFso)\n",
        "\n",
        "## Background\n",
        "Lamada, an e-commerce platform, currently relies on manual review analysis by customer support specialists and product analysts. This process is time-consuming, error-prone, and struggles to scale with increasing review volumes.\n",
        "\n",
        "## Project Goal\n",
        "Implement automated sentiment analysis to improve the efficiency and accuracy of review processing at Lamada.\n",
        "\n",
        "## Benefits of Automated Sentiment Analysis\n",
        "- Real-time processing for quicker customer feedback responses\n",
        "- Systematic identification of common themes and issues\n",
        "- Data-driven insights for targeted marketing strategies\n",
        "- Efficient prioritization of customer support tasks\n",
        "- Trend analysis for product satisfaction and inventory management\n",
        "\n",
        "In this project, you will develop a machine learning model to automate the sentiment analysis process, addressing Lamada's current challenges and unlocking these benefits.\n",
        "\n",
        "## MLOps Focus\n",
        "This greenfield project presents an opportunity to address issues that have historically challenged machine learning teams at Lamada. By implementing MLOps best practices, we aim to enhance the entire ML lifecycle, resulting in:\n",
        "\n",
        "- Improved model quality and reliability\n",
        "- Faster development and deployment cycles\n",
        "- Better collaboration between data scientists and operations teams\n",
        "- Increased reproducibility of results\n",
        "- Enhanced monitoring and maintenance of models in production\n",
        "\n",
        "In the following section we will be diving into the actual data that we have at hand at this point of time and performing some quick EDA on it in order to understand the data and all its quirks."
      ],
      "metadata": {
        "id": "y8CGfcqjb8nW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9p9eoQGoOepi"
      },
      "outputs": [],
      "source": [
        "# Installing all the necessary packages\n",
        "\n",
        "!pip install \\\n",
        "ucimlrepo \\\n",
        "ydata-profiling \\\n",
        "pandas \\\n",
        "snorkel \\\n",
        "ipytest \\\n",
        "pytest \\\n",
        "great_expectations==0.18.19 \\\n",
        "scikit-learn \\\n",
        "wandb \\\n",
        "skl2onnx \\\n",
        "onnxruntime \\\n",
        "checklist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "\n",
        "## Importance of EDA in Sentiment Analysis\n",
        "\n",
        "Exploratory Data Analysis is a crucial step in any data science project, particularly in sentiment analysis. For our Lamada e-commerce platform project using the Drugs.com dataset, EDA will help us:\n",
        "\n",
        "1. Understand the data distribution and quality\n",
        "2. Identify patterns and relationships between variables\n",
        "3. Detect anomalies or outliers that might affect our model\n",
        "4. Inform feature engineering and selection\n",
        "5. Guide our choice of machine learning algorithms\n",
        "\n",
        "## Key Areas to Explore\n",
        "\n",
        "Given the structure of our Drugs.com dataset, we should focus on:\n",
        "\n",
        "1. Text Analysis:\n",
        "   - Review length distribution\n",
        "   - Common words and phrases\n",
        "   - Correlation between review text and ratings\n",
        "\n",
        "2. Rating Distribution:\n",
        "   - Overall rating distribution\n",
        "   - Rating patterns across different drugs and conditions\n",
        "\n",
        "3. Temporal Trends:\n",
        "   - Changes in sentiment over time\n",
        "   - Seasonal patterns in reviews or ratings\n",
        "\n",
        "4. Drug and Condition Analysis:\n",
        "   - Most reviewed drugs and conditions\n",
        "   - Relationship between conditions and ratings\n",
        "\n",
        "5. Useful Count Analysis:\n",
        "   - Distribution of useful votes\n",
        "   - Correlation between usefulness and sentiment\n",
        "\n",
        "## Potential Challenges\n",
        "\n",
        "During EDA, we need to be aware of:\n",
        "\n",
        "1. Class Imbalance: The rating distribution might be skewed, affecting our model's performance.\n",
        "\n",
        "2. Data Quality: Look for missing values, inconsistencies in drug names or conditions, and potential data entry errors.\n",
        "\n",
        "3. Text Preprocessing Needs: Identify requirements for text cleaning, such as handling abbreviations, misspellings, or medical jargon.\n",
        "\n",
        "4. Bias Detection: Check for potential biases in the data, such as overrepresentation of certain drugs or conditions.\n",
        "\n",
        "5. Feature Relevance: Assess which features contribute most to sentiment and which might introduce noise.\n"
      ],
      "metadata": {
        "id": "oNvAiE_mH5H0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetching the dataset that we will be using throughout this course.\n",
        "# Read more about it here: https://archive.ics.uci.edu/dataset/462/drug+review+dataset+drugs+com\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "drug_reviews_drugs_com = fetch_ucirepo(id=462)\n",
        "df = pd.concat([drug_reviews_drugs_com.data.features, drug_reviews_drugs_com.data.targets])"
      ],
      "metadata": {
        "id": "yAymo7CDTCVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "ee-QZb0MUpG8",
        "outputId": "186f50c6-e705-4e0a-ff8b-248e9a45306c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   drugName                     condition  \\\n",
              "0                 Valsartan  Left Ventricular Dysfunction   \n",
              "1                Guanfacine                          ADHD   \n",
              "2                    Lybrel                 Birth Control   \n",
              "3                Ortho Evra                 Birth Control   \n",
              "4  Buprenorphine / naloxone             Opiate Dependence   \n",
              "\n",
              "                                              review  rating       date  \\\n",
              "0  \"It has no side effect, I take it in combinati...       9  20-May-12   \n",
              "1  \"My son is halfway through his fourth week of ...       8  27-Apr-10   \n",
              "2  \"I used to take another oral contraceptive, wh...       5  14-Dec-09   \n",
              "3  \"This is my first time using any form of birth...       8   3-Nov-15   \n",
              "4  \"Suboxone has completely turned my life around...       9  27-Nov-16   \n",
              "\n",
              "   usefulCount  \n",
              "0           27  \n",
              "1          192  \n",
              "2           17  \n",
              "3           10  \n",
              "4           37  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8244c3ef-ce70-45b7-b2b8-a51a74e63c35\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>drugName</th>\n",
              "      <th>condition</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>usefulCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Valsartan</td>\n",
              "      <td>Left Ventricular Dysfunction</td>\n",
              "      <td>\"It has no side effect, I take it in combinati...</td>\n",
              "      <td>9</td>\n",
              "      <td>20-May-12</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Guanfacine</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>\"My son is halfway through his fourth week of ...</td>\n",
              "      <td>8</td>\n",
              "      <td>27-Apr-10</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lybrel</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
              "      <td>5</td>\n",
              "      <td>14-Dec-09</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ortho Evra</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>\"This is my first time using any form of birth...</td>\n",
              "      <td>8</td>\n",
              "      <td>3-Nov-15</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Buprenorphine / naloxone</td>\n",
              "      <td>Opiate Dependence</td>\n",
              "      <td>\"Suboxone has completely turned my life around...</td>\n",
              "      <td>9</td>\n",
              "      <td>27-Nov-16</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8244c3ef-ce70-45b7-b2b8-a51a74e63c35')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8244c3ef-ce70-45b7-b2b8-a51a74e63c35 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8244c3ef-ce70-45b7-b2b8-a51a74e63c35');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2126a45-41d7-452b-897f-18399545e03f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2126a45-41d7-452b-897f-18399545e03f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2126a45-41d7-452b-897f-18399545e03f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quick & Easy EDA using Ydata-Profilling\n",
        "\n",
        "While manual EDA is crucial for deep understanding, we can accelerate our initial data exploration using automated tools. For this project, we'll be utilizing [ydata-profiling](https://github.com/ydataai/ydata-profiling), a powerful library that generates comprehensive exploratory data analysis reports.\n",
        "\n",
        "### Benefits of ydata-profiling\n",
        "\n",
        "1. **Speed**: Quickly generates an in-depth EDA report, saving time in the initial exploration phase.\n",
        "2. **Comprehensiveness**: Provides a wide range of statistics and visualizations for each variable in the dataset.\n",
        "3. **Interactivity**: Creates an interactive HTML report that allows for easy navigation and exploration.\n",
        "4. **Correlation Analysis**: Automatically detects and visualizes relationships between variables.\n",
        "5. Missing Data Overview **bold text**: Clearly highlights missing data patterns across the dataset.\n",
        "\n",
        "While ydata-profiling will provide us with a solid starting point, remember that *it's a complement to, not a replacement for, thoughtful manual EDA*. We'll use its insights as a springboard for more targeted analysis and feature engineering."
      ],
      "metadata": {
        "id": "R4KRX2qnIn7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "profile = ProfileReport(df, title=\"Drug Reviews Dataset Profiling Report\")"
      ],
      "metadata": {
        "id": "ebZk6YejTskL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile.to_notebook_iframe()"
      ],
      "metadata": {
        "id": "IKe13v2vU5Uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyzing the ydata-profiling Report\n",
        "\n",
        "Now that you've generated the ydata-profiling report for our Drugs.com dataset, it's time to dive in and extract meaningful insights.\n",
        "\n",
        "## [TODO]Add in your observations\n",
        "1. List at least five interesting findings from the report.\n",
        "2. Identify any potential data quality issues that need addressing.\n",
        "3. Based on this initial analysis, propose three hypotheses about sentiment in drug reviews that we could test in our deeper analysis.\n",
        "\n",
        "Remember, this automated report is a starting point. Use these insights to guide your manual EDA and feature engineering in the next steps of our project.\n",
        "\n",
        "```\n",
        "YOUR ANSWER GOES HERE\n",
        "```"
      ],
      "metadata": {
        "id": "pqorGO17JjU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Designing the ML System\n",
        "\n",
        "Before diving into model development, it's crucial to plan and scope out our machine learning project. This ensures that we're building a system that meets stakeholders' needs and aligns with business objectives. We'll use the Machine Learning Canvas to structure our planning process.\n",
        "\n",
        "## Project Expectations from Stakeholders\n",
        "\n",
        "Imagine the following stakeholder requests for our sentiment analysis system at Lamada:\n",
        "\n",
        "- Chief Customer Officer (CCO): \"We need a system that can automatically categorize the sentiment of drug reviews in real-time. This will help us respond quickly to negative feedback and highlight positive experiences.\"\n",
        "- Head of Product: \"The system should be able to process reviews as they come in, with a latency of no more than 200ms per review. We want to use this data to inform our product recommendations and marketing strategies.\"\n",
        "- CTO: \"We need to ensure the system can handle our current load of about 1000 reviews per hour, with the ability to scale up to 5000 reviews per hour during peak times.\"\n",
        "\n",
        "## Machine Learning Canvas Overview\n",
        "\n",
        "Let's break down each component of the Machine Learning Canvas and what you should consider:\n",
        "\n",
        "1. **Background**:\n",
        "   - Consider Lamada's current manual review process and its limitations.\n",
        "   - Think about the volume of reviews and the impact of slow response times on customer satisfaction.\n",
        "\n",
        "2. **Value Proposition**:\n",
        "   - How will automated sentiment analysis improve Lamada's operations and customer experience?\n",
        "   - What specific pain points will this solution address?\n",
        "\n",
        "3. **Objectives**:\n",
        "   - Break down the high-level goal of \"sentiment analysis\" into specific, measurable objectives.\n",
        "   - Consider accuracy targets, processing speed, and scalability requirements.\n",
        "\n",
        "4. **Solution**:\n",
        "   - Outline the key features of your sentiment analysis system.\n",
        "   - Consider how it will integrate with Lamada's existing e-commerce platform.\n",
        "   - Define what's in scope (e.g., English language reviews) and out of scope (e.g., image-based reviews).\n",
        "\n",
        "5. **Feasibility**:\n",
        "   - Assess if you have the necessary data, computational resources, and expertise to build this system.\n",
        "   - Consider any potential technical or ethical challenges.\n",
        "\n",
        "6. **Data**:\n",
        "   - Describe the Drugs.com dataset and how it will be used for training.\n",
        "   - Consider how you'll handle real-time incoming review data in production.\n",
        "   - Think about data privacy and security considerations.\n",
        "\n",
        "7. **Metrics**:\n",
        "   - Define key performance indicators (KPIs) for your model, such as accuracy, F1 score, and latency.\n",
        "   - Consider business metrics like customer satisfaction scores or response time improvements.\n",
        "\n",
        "8. **Evaluation**:\n",
        "   - Design your offline evaluation strategy using the Drugs.com dataset.\n",
        "   - Plan how you'll conduct online evaluation once the system is deployed.\n",
        "\n",
        "9. **Modeling**:\n",
        "   - Outline your approach to building the sentiment analysis model.\n",
        "   - Consider starting with a baseline model and iterating to more complex approaches.\n",
        "\n",
        "10. **Inference**:\n",
        "    - Based on the stakeholder requirements, you'll need to design for real-time inference.\n",
        "    - Consider how to optimize your model for low-latency predictions.\n",
        "\n",
        "11. **Feedback**:\n",
        "    - Plan how you'll collect feedback on the model's performance in production.\n",
        "    - Consider implementing a human-in-the-loop system for reviewing uncertain predictions.\n",
        "\n",
        "12. **Project**:\n",
        "    - Outline the team members needed (e.g., data scientists, ML engineers, DevOps).\n",
        "    - Create a timeline for development, testing, and deployment phases.\n",
        "\n",
        "\n",
        "![ML Canvas](https://drive.google.com/uc?id=1j1dXJ3PLdpbvbAMIeyUNAL-vJjiV8P-w)\n",
        "\n",
        "## [OPTIONAL] Fill up the ML Canvas\n",
        "Go through the notebook and finish the minimum requirements before filling out the Machine Learning Canvas for our Lamada sentiment analysis project. Be sure to consider the stakeholder requirements and the insights gained from our EDA phase. This canvas will serve as a roadmap for the rest of our project, ensuring that we're building a system that meets both technical and business needs. Make sure to include how we can create ground truth labels for this use case(we could for example, use the `rating` to map scores that are `1` to be `Negative` and `10` to be `Positive`).\n",
        "\n",
        "**Disclaimer**:\n",
        "For the purposes of this course project, you are not required to fill out all sections of the Machine Learning Canvas in full detail. Specifically, the \"Project\" section, including team member requirements and timelines, is optional. However, we encourage you to think about these aspects as they are crucial in real-world ML projects. Considering the full spectrum of project planning will give you a more comprehensive understanding of what goes into deploying a machine learning system in a production environment.\n",
        "\n",
        "Focus primarily on the technical aspects such as the data, modeling, metrics, and evaluation strategies. These elements will directly inform the implementation phase of our project. The business and operational considerations (like team composition and timelines) are included to give you a holistic view of ML project planning, which will be valuable in your future career.\n",
        "\n",
        "```\n",
        "YOUR ANSWER GOES HERE\n",
        "```"
      ],
      "metadata": {
        "id": "q3a0nwRvaRkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation\n",
        "\n",
        "While our Drugs.com dataset is conveniently packaged for this project, it's important to understand that in real-world scenarios like Lamada, data is rarely so neatly organized. Let's explore how data is typically handled in production environments.\n",
        "\n",
        "## Data in the Wild: The Reality of Enterprise Data\n",
        "\n",
        "In most enterprises, including e-commerce platforms like Lamada, data is:\n",
        "\n",
        "1. Distributed: Stored across multiple databases, data lakes, and other storage systems.\n",
        "2. Heterogeneous: Comes in various formats (structured, semi-structured, and unstructured).\n",
        "3. Dynamic: Constantly updated and growing.\n",
        "4. Raw: Often requires significant processing before it's usable for analysis or modeling.\n",
        "\n",
        "## The Role of Data Engineering\n",
        "\n",
        "Data Engineers play a crucial role in making raw data usable for Data Scientists. Their responsibilities include:\n",
        "\n",
        "1. Data Integration: Combining data from various sources.\n",
        "2. Data Transformation: Converting data into a suitable format for analysis.\n",
        "3. Data Quality Assurance: Ensuring data accuracy, completeness, and consistency.\n",
        "4. Data Pipeline Management: Creating and maintaining data flows.\n",
        "\n",
        "## ETL vs ELT Processes\n",
        "\n",
        "\n",
        "![ELT Pipeline](https://drive.google.com/uc?id=11AGHxqmvfNgYGCL7kZmInyQhxml0X-6r)\n",
        "\n",
        "Two common approaches to data preparation are:\n",
        "\n",
        "1. Extract, Transform, Load (ETL):\n",
        "   - Data is extracted from source systems.\n",
        "   - Transformed to fit operational needs.\n",
        "   - Loaded into the target system (e.g., Data Warehouse).\n",
        "\n",
        "2. Extract, Load, Transform (ELT):\n",
        "   - Data is extracted from source systems.\n",
        "   - Loaded into the target system in its original format.\n",
        "   - Transformed within the target system as needed.\n",
        "\n",
        "ELT is becoming increasingly popular due to the decreasing cost of storage and the increasing power of modern data warehouses to handle transformations.\n",
        "\n",
        "## Data Warehouses and Their Role\n",
        "\n",
        "\n",
        "![Data Systems](https://drive.google.com/uc?id=1Rd1WLEm30gWlJzaJiQXEzlFQ6mJNWfMl)\n",
        "\n",
        "\n",
        "Data Warehouses like Snowflake, AWS Redshift, or Google BigQuery serve as centralized repositories for integrated data from various sources. They offer:\n",
        "\n",
        "1. Scalability: Can handle large volumes of data.\n",
        "2. Performance: Optimized for complex queries and analytics.\n",
        "3. Integration: Can combine data from multiple sources.\n",
        "4. Historical Data: Maintain historical records for trend analysis.\n",
        "\n",
        "## From Raw Data to ML-Ready Datasets\n",
        "\n",
        "For our Lamada sentiment analysis project, the process might look like this:\n",
        "\n",
        "1. Data Collection:\n",
        "   - Customer reviews are collected from web forms, mobile apps, and customer service interactions.\n",
        "   - Product information is stored in product databases.\n",
        "   - User data is kept in customer relationship management (CRM) systems.\n",
        "\n",
        "2. Data Integration:\n",
        "   - Data Engineers create pipelines to extract this data from various sources.\n",
        "   - The data is loaded into a staging area in the Data Warehouse.\n",
        "\n",
        "3. Data Transformation:\n",
        "   - Engineers apply transformations to clean the data (e.g., handling missing values, standardizing formats).\n",
        "   - They join different tables to create a unified view of reviews with associated metadata.\n",
        "\n",
        "4. Feature Engineering:\n",
        "   - Data Scientists work with the integrated data to create relevant features.\n",
        "   - This might include text preprocessing, sentiment score calculation, or deriving new features from existing data.\n",
        "\n",
        "5. Data Labelling:\n",
        "   - If manual labelling is required (e.g., for a subset of reviews to train or validate the model), a labelling workflow is set up.\n",
        "   - This could involve a team of human annotators or a crowdsourcing platform.\n",
        "\n",
        "6. Dataset Creation:\n",
        "   - The final ML-ready dataset is created, combining the engineered features and labels.\n",
        "   - This dataset is versioned and stored, often in a format optimized for ML workflows (e.g., Parquet files in a data lake).\n",
        "\n",
        "## Data Quality Checks\n",
        "\n",
        "### Importance of Data Quality Checks\n",
        "\n",
        "Data quality is crucial for any machine learning project. Poor data quality can lead to unreliable models, incorrect insights, and wasted time and resources. Implementing data quality checks on raw data is essential because:\n",
        "\n",
        "1. **Garbage In, Garbage Out**: The quality of your model's output is directly dependent on the quality of input data.\n",
        "\n",
        "2. **Early Error Detection**: Catching data issues early in the pipeline saves time and prevents downstream problems.\n",
        "\n",
        "3. **Consistency**: Ensures that data meets predefined standards and is consistent across different batches or sources.\n",
        "\n",
        "4. **Trust**: Builds confidence in the data and subsequent analysis among stakeholders.\n",
        "\n",
        "5. **Compliance**: Helps meet regulatory requirements in industries where data quality is mandated.\n",
        "\n",
        "6. **Efficiency**: Automates the process of data validation, reducing manual checks and human error.\n",
        "\n",
        "7. **Documentation**: Creates a clear record of data expectations and quality over time.\n"
      ],
      "metadata": {
        "id": "SEDRxq3aZwG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [TODO] Implementing Data Quality Checks with Great Expectations\n",
        "\n",
        "Great Expectations is a powerful tool for data validation and documentation. It allows you to express what you \"expect\" from your data and then validates those expectations.\n",
        "\n",
        "[**TODO**]: Implement the following data quality checks using Great Expectations for our Drugs.com review dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "l502e33a0kv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!great_expectations init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Lv0GkpwDVHB",
        "outputId": "3bdb0b9d-695b-40aa-a1ca-c23aec743d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m\n",
            "  ___              _     ___                  _        _   _\n",
            " / __|_ _ ___ __ _| |_  | __|_ ___ __  ___ __| |_ __ _| |_(_)___ _ _  ___\n",
            "| (_ | '_/ -_) _` |  _| | _|\\ \\ / '_ \\/ -_) _|  _/ _` |  _| / _ \\ ' \\(_-<\n",
            " \\___|_| \\___\\__,_|\\__| |___/_\\_\\ .__/\\___\\__|\\__\\__,_|\\__|_\\___/_||_/__/\n",
            "                                |_|\n",
            "             ~ Always know what to expect from your data ~\n",
            "\u001b[0m\n",
            "This looks like an existing project that \u001b[32mappears complete!\u001b[0m You are \u001b[32mready to roll.\u001b[0m\n",
            "\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import great_expectations as gx\n",
        "from great_expectations.dataset import PandasDataset\n",
        "\n",
        "context = gx.get_context()\n",
        "\n",
        "datasource = context.sources.add_pandas(name=\"my_pandas_datasource\")\n",
        "data_asset = datasource.add_dataframe_asset(name=\"drug_reviews\", dataframe=df)\n",
        "\n",
        "# Create an Expectation Suite\n",
        "expectation_suite_name = \"drug_reviews_suite\"\n",
        "context.add_or_update_expectation_suite(expectation_suite_name=expectation_suite_name)\n",
        "\n",
        "# Create a validator\n",
        "validator = context.get_validator(\n",
        "    datasource_name=\"my_pandas_datasource\",\n",
        "    data_asset_name=\"drug_reviews\",\n",
        "    expectation_suite_name=expectation_suite_name\n",
        ")"
      ],
      "metadata": {
        "id": "kaZDEArfEge_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Refer to the GX Expectations Gallery\n",
        "# Solve this section https://greatexpectations.io/expectations\n",
        "\n",
        "# TODO 1: Check for the presence and order of all expected columns\n",
        "# Hint: This expectation ensures that the table has exactly these columns in this order\n",
        "\n",
        "# TODO 2: Ensure 'rating' is between 1 and 10\n",
        "# Hint: This expectation checks if all values in the 'rating' column are within the specified range\n",
        "\n",
        "# TODO 3: Check that 'review' column doesn't contain null values\n",
        "# Hint: This expectation verifies that there are no null values in the 'review' column\n",
        "\n",
        "\n",
        "# TODO 4: Verify that 'usefulCount' is non-negative\n",
        "# Hint: This expectation ensures all values in 'usefulCount' are greater than or equal to zero\n",
        "\n",
        "validator.save_expectation_suite(discard_failed_expectations=False)\n",
        "\n",
        "checkpoint_name = \"my_checkpoint\"\n",
        "checkpoint = context.add_or_update_checkpoint(\n",
        "    name=checkpoint_name,\n",
        "    validator=validator,\n",
        ")\n",
        "\n",
        "checkpoint_result = checkpoint.run()\n",
        "\n",
        "print(checkpoint_result)"
      ],
      "metadata": {
        "id": "HXSAWcbqEcbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [OPTIONAL]Create more checks for the data\n",
        "\n",
        "In this section you can try performing more checks based on the ones we have listed down below or feel free to add in checks that you feel would be suitable for our use case!"
      ],
      "metadata": {
        "id": "tusqb0QZFk2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO 1: Check for the presence and order of all expected columns\n",
        "# Hint: Use expect_table_columns_to_match_ordered_list() method\n",
        "# Expected columns: \"drugName\", \"condition\", \"review\", \"rating\", \"date\", \"usefulCount\"\n",
        "\n",
        "# TODO 2: Ensure 'rating' is between 1 and 10\n",
        "# Hint: Use expect_column_values_to_be_between() method\n",
        "\n",
        "# TODO 3: Check that 'review' column doesn't contain null values\n",
        "# Hint: Use expect_column_values_to_not_be_null() method\n",
        "\n",
        "# TODO 4: Verify that 'usefulCount' is non-negative\n",
        "# Hint: Use expect_column_values_to_be_between() method with only a min_value\n",
        "\n",
        "# TODO 5: Ensure 'date' follows the expected format (DD-Mon-YY)\n",
        "# Hint: Use expect_column_values_to_match_strftime_format() method\n",
        "# The strftime format for DD-Mon-YY is \"%d-%b-%y\"\n",
        "\n",
        "checkpoint_name = \"my_checkpoint\"\n",
        "checkpoint = context.add_or_update_checkpoint(\n",
        "    name=checkpoint_name,\n",
        "    validator=validator,\n",
        ")\n",
        "\n",
        "checkpoint_result = checkpoint.run()\n",
        "\n",
        "print(checkpoint_result)"
      ],
      "metadata": {
        "id": "RfZDKY37Fdhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Labeling for Sentiment Analysis\n",
        "\n",
        "Looking at our sample dataset, we can see that we have reviews with associated ratings. For our sentiment analysis task, we need to convert these ratings into sentiment labels. Let's explore different labeling techniques:\n",
        "\n",
        "### 1. Natural Labels\n",
        "\n",
        "In our case, we're fortunate to have natural labels in the form of ratings.\n",
        "> Tasks with natural labels are tasks where the model's predictions can be automatically evaluated or partially evaluated by the system.\n",
        "These ratings can be used to infer sentiment without additional manual labeling.\n",
        "\n",
        "### 2. Threshold-Based Labeling(Programmatic Labeling)\n",
        "\n",
        "![Programmatic Labeling](https://drive.google.com/uc?id=1Esp2XapZggGpyUyST5X_clzlrIQnTRfo)\n",
        "\n",
        "A simple approach to start with:\n",
        "- `Ratings 1-4`: Negative sentiment\n",
        "- `Ratings 5-6`: Neutral sentiment\n",
        "- `Ratings 7-10`: Positive sentiment\n",
        "\n",
        "This method is quick and easy but may oversimplify the nuances in the reviews. You can use a tool like [Snorkel](https://github.com/snorkel-team/snorkel) for this task.\n",
        "\n",
        "### 3. Hand Labeling\n",
        "\n",
        "![Hand Labeling](https://drive.google.com/uc?id=14tb6DFFpe3ApCYlI8n0vnBv5MM7Z6Xtf)\n",
        "\n",
        "For more nuanced labeling, we could manually review a subset of the data:\n",
        "- Read each review\n",
        "- Assign a sentiment label (Negative, Neutral, Positive)\n",
        "- Consider the rating as a guide, but allow for discrepancies\n",
        "\n",
        "While this method can be more accurate, it's **time-consuming**, and where bias easily creeps in, and may not be feasible for large datasets.\n",
        "\n",
        "### 4. LLM-Assisted Labeling\n",
        "![Data Labelling using LLMs](https://drive.google.com/uc?id=1jRIMZFUUDr3_03I6btVsOlv6y9thlcZA)\n",
        "\n",
        "Large Language Models (LLMs) have revolutionized the labeling process:\n",
        "- Use an LLM to analyze the review text and suggest a sentiment label\n",
        "- Optionally, have a human review the LLM's suggestions for quality control\n",
        "\n",
        "This method can significantly speed up the labeling process while maintaining high quality. More information about it can be found [here](https://www.refuel.ai/blog-posts/llm-labeling-technical-report).\n",
        "\n",
        "### 5. Active Learning\n",
        "\n",
        "![Active Learning](https://drive.google.com/uc?id=1xEUrPHaKHSA4G9PYGA35013QbdHRwvfl)\n",
        "\n",
        "\n",
        "\n",
        "If resources are limited:\n",
        "1. Label a small initial dataset\n",
        "2. Train a model on this dataset\n",
        "3. Use the model to predict labels for unlabeled data\n",
        "4. Select the most uncertain predictions for human review\n",
        "5. Add these newly labeled examples to the training set\n",
        "6. Repeat steps 2-5\n",
        "\n",
        "This iterative process can efficiently improve your model with minimal labeling effort.\n",
        "\n",
        "If you would like to dive a bit deeper into Active Learning then check out this [video](https://youtu.be/7kX6rhUGtzA?si=sLhi6gRZFaPeMA4X) about the topic.\n",
        "\n",
        "For our project, let's start with the threshold-based approach for quick results. As we progress, we can explore LLM-assisted labeling to refine our dataset and potentially improve model performance.\n",
        "\n",
        "Remember, the quality of your labels directly impacts your model's performance. Always validate a sample of your labels, regardless of the method used."
      ],
      "metadata": {
        "id": "sw42Ic3tCjTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from snorkel.labeling import labeling_function, PandasLFApplier, LFAnalysis\n",
        "import pytest\n",
        "import ipytest\n",
        "\n",
        "ipytest.autoconfig()\n",
        "\n",
        "# TODO: Create the labeling function based on the threshold we created and\n",
        "# leveraging the LABEL_MAPPING below:\n",
        "# Label 0 => Ratings 1-4: Negative sentiment\n",
        "# Label 1 => Ratings 5-6: Neutral sentiment\n",
        "# Label 2 => Ratings 7-10: Positive sentiment\n",
        "\n",
        "LABEL_MAPPING = {\n",
        "    \"NEGATIVE\": 0,\n",
        "    \"NEUTRAL\": 1,\n",
        "    \"POSITIVE\": 2,\n",
        "}\n",
        "\n",
        "@labeling_function()\n",
        "def label_sentiment(x):\n",
        "  # TODO: Add your code here"
      ],
      "metadata": {
        "id": "B8rhm--r8ttC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_data(df):\n",
        "    lf_applier = PandasLFApplier([label_sentiment])\n",
        "    labels = lf_applier.apply(df)\n",
        "    df['sentiment_label'] = labels\n",
        "    return df"
      ],
      "metadata": {
        "id": "uDg-H25Q-G0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -vv -s\n",
        "\n",
        "@pytest.mark.parametrize(\"rating, expected_label\", [\n",
        "    (2, 0),\n",
        "    (5, 1),\n",
        "    (7, 2),\n",
        "    (10, 2),\n",
        "    (1, 0),\n",
        "    (3, 0),\n",
        "    (4, 0),\n",
        "    (6, 1),\n",
        "    (8, 2),\n",
        "])\n",
        "def test_sentiment_labeling(rating, expected_label):\n",
        "    # Create a sample dataframe with a single row\n",
        "    data = {\n",
        "        'drugName': ['Drug A'],\n",
        "        'condition': ['Condition A'],\n",
        "        'review': ['Review A'],\n",
        "        'rating': [rating],\n",
        "        'date': ['2022-01-01'],\n",
        "        'usefulCount': [10]\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    labeled_df = label_data(df)\n",
        "    assert labeled_df['sentiment_label'].iloc[0] == expected_label, f\"Labeling doesn't match expected output for rating {rating}\"\n",
        "    assert all(labeled_df[col].iloc[0] == df[col].iloc[0] for col in df.columns), \"Original data was modified\"\n",
        "    assert 'sentiment_label' in labeled_df.columns, \"sentiment_label column not added\""
      ],
      "metadata": {
        "id": "b8-nwykV-aj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [OPTIONAL]LLM-Assisted Labeling\n",
        "\n",
        "In this section, you'll explore how to use a Large Language Model (LLM) to assist in labeling our dataset.\n",
        "This can be especially useful for more nuanced sentiment analysis or when dealing with large datasets.\n",
        "\n",
        "Steps to complete:\n",
        "1. Choose an LLM API (e.g., OpenAI's GPT-3, Hugging Face's API, or any other accessible LLM)\n",
        "2. Set up the necessary API credentials\n",
        "3. Create a function to send reviews to the LLM and interpret its responses\n",
        "4. Apply the LLM labeling to a subset of our data\n",
        "5. Compare LLM-generated labels with our rule-based labels\n",
        "\n",
        "**NOTE**: Be mindful of API usage costs and rate limits when using LLM services.\n",
        "\n",
        "You could also try out [autolabel](https://github.com/refuel-ai/autolabel) which does all of this right out of the box for you!\n",
        "\n",
        "**Discussion Questions**:\n",
        "1. How does the agreement rate between rule-based and LLM-generated labels compare?\n",
        "2. In cases of disagreement, which labeling method seems more accurate? Why?\n",
        "3. What are the pros and cons of using an LLM for labeling compared to our rule-based approach?"
      ],
      "metadata": {
        "id": "GOk_XnGABF-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIONAL TASKS GOES HERE"
      ],
      "metadata": {
        "id": "OpSN1mWHCOyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Quality Checks on Features\n"
      ],
      "metadata": {
        "id": "dMvsEg38NZRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "labels = label_data(df)\n",
        "sentiment_df = labels[['review', 'sentiment_label']]\n",
        "sentiment_df = sentiment_df.rename(columns={'review': 'text', 'sentiment_label': 'label'})\n",
        "train_df, test_df = train_test_split(sentiment_df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Sample of sentiment_df:\")\n",
        "print(sentiment_df.head())\n",
        "\n",
        "print(f\"\\nTrain set shape: {train_df.shape}\")\n",
        "print(f\"Test set shape: {test_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UorvjVcXOAT",
        "outputId": "4b60255e-0338-4572-a9c0-94de743e202b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 215063/215063 [00:11<00:00, 17972.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of sentiment_df:\n",
            "                                                text  label\n",
            "0  \"It has no side effect, I take it in combinati...      2\n",
            "1  \"My son is halfway through his fourth week of ...      2\n",
            "2  \"I used to take another oral contraceptive, wh...      1\n",
            "3  \"This is my first time using any form of birth...      2\n",
            "4  \"Suboxone has completely turned my life around...      2\n",
            "\n",
            "Train set shape: (172050, 2)\n",
            "Test set shape: (43013, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import great_expectations as gx\n",
        "from great_expectations.dataset import PandasDataset\n",
        "import pandas as pd\n",
        "\n",
        "def perform_data_quality_checks(train_df, test_df):\n",
        "    train_ge = gx.dataset.PandasDataset(train_df)\n",
        "    test_ge = gx.dataset.PandasDataset(test_df)\n",
        "\n",
        "    print(\"Performing data quality checks on processed data...\")\n",
        "\n",
        "    # TODO: Check that the labels are of values 0, 1, 2\n",
        "    # Hint: Use the expect_column_values_to_be_in_set() method\n",
        "\n",
        "    print(\"\\n1. Checking label values:\")\n",
        "    # Print results here\n",
        "\n",
        "    # TODO: Verify that we only have columns text and label\n",
        "    # Hint: Use the expect_table_columns_to_match_ordered_list() method\n",
        "\n",
        "    print(\"\\n2. Checking columns:\")\n",
        "    # Print results here\n",
        "\n",
        "    # TODO: Check for data leakage between train and test data on text\n",
        "    # Hint: Compare the 'text' columns of train and test dataframes\n",
        "    # Look for any duplicate texts between the two datasets\n",
        "\n",
        "    print(\"\\n3. Checking for data leakage:\")\n",
        "    # Print results here\n",
        "\n",
        "    # TODO: Check for duplicates in each dataset\n",
        "    # Hint: Use the expect_column_values_to_be_unique() method on the 'text' column\n",
        "\n",
        "    print(\"\\n4. Checking for duplicate reviews within each dataset:\")\n",
        "    # Print results here\n",
        "\n",
        "    # TODO: Update overall success check\n",
        "    # Hint: Combine the results of all previous checks\n",
        "\n",
        "    print(\"\\nOverall data quality check result:\", \"Passed\" if overall_success else \"Failed\")\n",
        "    return overall_success\n",
        "\n",
        "quality_check_passed = perform_data_quality_checks(train_df, test_df)\n",
        "\n",
        "if quality_check_passed:\n",
        "    print(\"All data quality checks passed. Proceeding with model training...\")\n",
        "else:\n",
        "    print(\"Data quality checks failed. Please address the issues before proceeding.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dPJT_XLUag6",
        "outputId": "6df1c70d-74fc-4e1c-e4bf-ee10c0c581fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing data quality checks on processed data...\n",
            "\n",
            "1. Checking label values:\n",
            "Train data: True\n",
            "Test data: True\n",
            "\n",
            "2. Checking columns:\n",
            "Train data: True\n",
            "Test data: True\n",
            "\n",
            "3. Checking for data leakage:\n",
            "WARNING: Found 27545 duplicate reviews in both train and test sets.\n",
            "This indicates data leakage!\n",
            "Sample of duplicates:\n",
            "- \"Fentora gave me my life back! But it is very hard to get it covered. They do, however, offer a coup...\n",
            "- \"I had spinal fusion several years ago and since have suffered pain. Recently my feet started tingli...\n",
            "- \"I had Mirena fitted 4 weeks ago and immediately I started with rashes and itching, first on my neck...\n",
            "\n",
            "4. Checking for duplicate reviews within each dataset:\n",
            "Train data (no duplicates): False\n",
            "Test data (no duplicates): False\n",
            "WARNING: Found 110601 duplicate reviews in train set.\n",
            "Sample of duplicates:\n",
            "- \"I have chronic panic disorder with agoraphobia and due to the fact I have not responded to any anti...\n",
            "- \"It seems to calm me but I am also an avid yoga participant so not always sure which is helping more...\n",
            "- \"Bottom line: Didn&#039;t work for me. I had wanted to try this a few years back but it was too expe...\n",
            "WARNING: Found 7102 duplicate reviews in test set.\n",
            "Sample of duplicates:\n",
            "- \"I had the Mirena inserted 9 months ago, it is now September and boy do I REGRET it! I got it to tre...\n",
            "- \"Chronic sinus and ear drainage\"...\n",
            "- \"I have struggled with migraines for 14 years. I have tried so many medications over the years. The ...\n",
            "\n",
            "Overall data quality check result: Failed\n",
            "Data quality checks failed. Please address the issues before proceeding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Addressing Data Issues\n",
        "\n",
        "Our data leakage check has revealed a significant number of duplicate reviews between the train and test sets. This is a critical issue that needs to be resolved before we can proceed with model training. There are a couple of things that we can do of varying complexity:\n",
        "\n",
        "### TODO: Drop Duplicates(Simple Fix)\n",
        "A simple fix that we can do is to just drop the duplicate rows that exists in the original dataset and then\n",
        "\n",
        "### [OPTIONAL] Investigate and Handle Duplicates\n",
        "Perform a deeper EDA into the dataset looking into why this happens in the first place and from there decide whether we should be\n",
        "\n"
      ],
      "metadata": {
        "id": "6H860bepYSlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(f\"Original dataset shape: {df.shape}\")\n",
        "labels = label_data(df)\n",
        "sentiment_df = labels[['review', 'sentiment_label']]\n",
        "sentiment_df = sentiment_df.rename(columns={'review': 'text', 'sentiment_label': 'label'})\n",
        "# TODO: Drop duplicates here\n",
        "df_deduplicated = ...\n",
        "print(f\"Shape after removing duplicates: {df_deduplicated.shape}\")\n",
        "\n",
        "train_df, test_df = train_test_split(df_deduplicated, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk5rQx6kQtyw",
        "outputId": "775d6cd6-d1c0-4adb-f90d-e8b4e6270eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (215063, 7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 215063/215063 [00:11<00:00, 18061.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after removing duplicates: (128478, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quality_check_passed = perform_data_quality_checks(train_df, test_df)\n",
        "\n",
        "if quality_check_passed:\n",
        "    print(\"All data quality checks passed. Proceeding with model training...\")\n",
        "else:\n",
        "    print(\"Data quality checks failed. Please review the processing steps.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKIQ3usGRJZH",
        "outputId": "3f9afb25-400c-483b-cd89-a617ccac0163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing data quality checks on processed data...\n",
            "\n",
            "1. Checking label values:\n",
            "Train data: True\n",
            "Test data: True\n",
            "\n",
            "2. Checking columns:\n",
            "Train data: True\n",
            "Test data: True\n",
            "\n",
            "3. Checking for data leakage:\n",
            "No duplicate reviews found between train and test sets.\n",
            "No evidence of data leakage detected.\n",
            "\n",
            "4. Checking for duplicate reviews within each dataset:\n",
            "Train data (no duplicates): True\n",
            "Test data (no duplicates): True\n",
            "\n",
            "Overall data quality check result: Passed\n",
            "All data quality checks passed. Proceeding with model training...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Development\n",
        "\n",
        "Now that we have prepared and validated our data, we can focus our efforts on modeling. Before diving into complex algorithms, it's crucial to establish a baseline model. This step, often overlooked, is fundamental in the machine learning development process.\n",
        "\n",
        "### The Importance of Baseline Models\n",
        "\n",
        "1. **Benchmark for Comparison**:\n",
        "   A baseline model provides a point of reference against which we can compare more sophisticated models. It helps answer the question: \"Is our complex model actually performing better than a simple approach?\"\n",
        "\n",
        "2. **Justification for Complexity**:\n",
        "   If a simple model performs nearly as well as a complex one, it may not be worth the additional computational cost and potential overfitting risk of the complex model.\n",
        "\n",
        "3. **Problem Understanding**:\n",
        "   Implementing a baseline forces us to understand the fundamental aspects of our problem and data.\n",
        "\n",
        "4. **Quick Insights**:\n",
        "   Baseline models can provide quick insights into the problem, potentially revealing simple patterns or biases in the data.\n",
        "\n",
        "5. **Sanity Check**:\n",
        "   If a complex model performs worse than the baseline, it's a clear sign that something is wrong – either with the model, the data, or our approach.\n",
        "\n",
        "### Baseline Models for Sentiment Analysis\n",
        "\n",
        "For our drug review sentiment analysis task, we can consider the following baseline approaches:\n",
        "\n",
        "**Majority Class Predictor**:\n",
        "Always predict the most common sentiment in our training data. This is the simplest possible baseline.\n",
        "\n",
        "```python\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "majority_baseline = DummyClassifier(strategy='most_frequent')\n",
        "majority_baseline.fit(X_train, y_train)\n",
        "majority_accuracy = majority_baseline.score(X_test, y_test)\n",
        "print(f\"Majority Class Baseline Accuracy: {majority_accuracy:.4f}\")\n",
        "```"
      ],
      "metadata": {
        "id": "rjD8rocKdOO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeZsNRoPYFe6",
        "outputId": "36f7b382-639e-42d1-ac6f-1af9304026c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myudhiesh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wandb\n",
        "import pandas as pd\n",
        "\n",
        "def save_and_log_datasets(train_df, test_df, y_probas, run):\n",
        "    \"\"\"\n",
        "    Save the split datasets and probabilities to CSV files and log them as artifacts in W&B.\n",
        "\n",
        "    Args:\n",
        "    train_df (pd.DataFrame): Training dataframe\n",
        "    test_df (pd.DataFrame): Test dataframe\n",
        "    y_probas (np.array): Predicted probabilities for test set, (n_samples, n_classes)\n",
        "    run (wandb.Run): The current W&B run\n",
        "    \"\"\"\n",
        "\n",
        "    os.makedirs('datasets', exist_ok=True)\n",
        "\n",
        "    train_df.to_csv('datasets/train.csv', index=False)\n",
        "    test_df.to_csv('datasets/test.csv', index=False)\n",
        "\n",
        "    probas_df = pd.DataFrame(y_probas, columns=LABELS)\n",
        "    probas_df.to_csv('datasets/test_probas.csv', index=False)\n",
        "\n",
        "    artifact = wandb.Artifact(name=\"drug-review-dataset\", type=\"dataset\")\n",
        "\n",
        "    artifact.add_file(local_path=\"datasets/train.csv\", name=\"train.csv\")\n",
        "    artifact.add_file(local_path=\"datasets/test.csv\", name=\"test.csv\")\n",
        "    artifact.add_file(local_path=\"datasets/test_probas.csv\", name=\"test_probas.csv\")\n",
        "\n",
        "    run.log_artifact(artifact)\n",
        "\n",
        "    print(\"Datasets and probabilities saved and logged as artifacts in W&B.\")"
      ],
      "metadata": {
        "id": "twqDRQyOCs5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = train_df[['text']].values.flatten(), train_df[['label']].values.flatten()\n",
        "X_test, y_test = test_df[['text']].values.flatten(), test_df[['label']].values.flatten()"
      ],
      "metadata": {
        "id": "OfVticfmZQPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def train_and_evaluate(model, X_train, y_train, X_test, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_probas = model.predict_proba(X_test)\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'f1': f1_score(y_test, y_pred, average='weighted'),\n",
        "        'precision': precision_score(y_test, y_pred, average='weighted'),\n",
        "        'recall': recall_score(y_test, y_pred, average='weighted')\n",
        "    }\n",
        "    # Ensure that we save the dataset used so that we can use it for debugging\n",
        "    # or in the future for comparisons with other models\n",
        "    save_and_log_datasets(train_df, test_df, y_probas, run)\n",
        "\n",
        "    for metric, value in metrics.items():\n",
        "        wandb.log({metric: value})\n",
        "\n",
        "    wandb.sklearn.plot_confusion_matrix(y_test, y_pred, labels=['Negative', 'Neutral', 'Positive'])\n",
        "    wandb.sklearn.plot_roc(y_test, y_probas, labels=['Negative', 'Neutral', 'Positive'])\n",
        "    wandb.sklearn.plot_precision_recall(y_test, y_probas, labels=['Negative', 'Neutral', 'Positive'])\n",
        "    wandb.sklearn.plot_class_proportions(y_train, y_test, ['Negative', 'Neutral', 'Positive'])\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Initialize W&B run\n",
        "wandb.init(project=\"Drug Review MLOps Uplimit\", name=\"DummyClassifier_Stratified\",\n",
        "           notes=\"Dummy Classifier Baseline\", tags=[\"baseline\", \"dummy\", \"stratified\"])\n",
        "\n",
        "config = {\n",
        "    \"model\": \"DummyClassifier\",\n",
        "    \"strategy\": \"stratified\"\n",
        "}\n",
        "wandb.config.update(config)\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy='stratified', random_state=42)\n",
        "dummy_metrics = train_and_evaluate(dummy_clf, X_train, y_train, X_test, y_test)\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "WJCIhLXAYEKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def check_batch_training(X, y, n_gram_size, max_iter, batch_size=32):\n",
        "    \"\"\"\n",
        "    Check if the model can train on a batch of specified size using a scikit-learn Pipeline.\n",
        "    \"\"\"\n",
        "    X_batch = X[:batch_size]\n",
        "    y_batch = y[:batch_size]\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('featurizer', CountVectorizer(ngram_range=(1, n_gram_size))),\n",
        "        ('classifier', LogisticRegression(max_iter=max_iter))\n",
        "    ])\n",
        "\n",
        "    try:\n",
        "      pipeline.fit(X_batch, y_batch)\n",
        "      return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error training on batch of size {batch_size}: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "# Perform batch check before main training loop\n",
        "print(\"Performing batch training check...\")\n",
        "N_GRAM_SIZE = 3\n",
        "LR_MAX_ITER = 100\n",
        "batch_success = check_batch_training(X_train, y_train, N_GRAM_SIZE, LR_MAX_ITER, batch_size=32)\n",
        "\n",
        "if not batch_success:\n",
        "    print(\"Batch training failed. Please review your model and data.\")\n",
        "else:\n",
        "    print(\"Batch training successful. Proceeding with full training...\")"
      ],
      "metadata": {
        "id": "_UvBII05afWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from skl2onnx import convert_sklearn\n",
        "from skl2onnx.common.data_types import StringTensorType\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Constants\n",
        "N_GRAM_SIZE = 3\n",
        "LR_MAX_ITER = 100\n",
        "TRAIN_SIZE_EVALS = [1000, 5000, 10000, len(X_train)]\n",
        "\n",
        "def train_and_evaluate(pipeline, X_train, y_train, X_test, y_test, run_name, run):\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    registered_model_name = \"review-sentiment-analysis-dev\"\n",
        "\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    y_probas = pipeline.predict_proba(X_test)\n",
        "\n",
        "    X_train_vec = pipeline.named_steps['featurizer'].transform(X_train)\n",
        "    X_test_vec = pipeline.named_steps['featurizer'].transform(X_test)\n",
        "\n",
        "    wandb.sklearn.plot_confusion_matrix(y_test, y_pred, labels=LABELS)\n",
        "    wandb.sklearn.plot_roc(y_test, y_probas, labels=LABELS)\n",
        "    wandb.sklearn.plot_precision_recall(y_test, y_probas, labels=LABELS)\n",
        "    wandb.sklearn.plot_class_proportions(y_train, y_test, LABELS)\n",
        "\n",
        "    save_and_log_datasets(train_df, test_df, y_probas, run)\n",
        "\n",
        "    # Export the model to ONNX format\n",
        "    initial_type = [('text_input', StringTensorType([None, 1]))]\n",
        "    onx = convert_sklearn(pipeline, initial_types=initial_type)\n",
        "\n",
        "    # Save the ONNX model locally\n",
        "    onnx_filename = f\"logreg_model_{run_name}.onnx\"\n",
        "    onnx_filepath = Path(onnx_filename)\n",
        "    with open(onnx_filepath, \"wb\") as f:\n",
        "        f.write(onx.SerializeToString())\n",
        "\n",
        "    run.link_model(\n",
        "        onnx_filepath,\n",
        "        registered_model_name\n",
        "    )\n",
        "\n",
        "    # Clean up the local file\n",
        "    os.remove(onnx_filepath)\n",
        "\n",
        "# OPTIONAL: Initially lets just train on a small sample if you have the time\n",
        "# go ahead and try training on the entire dataset!\n",
        "n = TRAIN_SIZE_EVALS[0]\n",
        "run_name = f\"LR_train_size_{n}\"\n",
        "run = wandb.init(project=\"Drug Review MLOps Uplimit\", name=run_name,\n",
        "            notes=\"Logistic Regression with various train sizes\",\n",
        "            tags=[\"logistic-regression\", \"experiment\"])\n",
        "\n",
        "config = {\n",
        "    \"model\": \"LogisticRegression\",\n",
        "    \"n_gram_size\": N_GRAM_SIZE,\n",
        "    \"max_iter\": LR_MAX_ITER,\n",
        "    \"train_size\": n\n",
        "}\n",
        "run.config.update(config)\n",
        "\n",
        "X_train_i = X_train[:n]\n",
        "y_train_i = y_train[:n]\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('featurizer', CountVectorizer(ngram_range=(1, N_GRAM_SIZE))),\n",
        "    ('classifier', LogisticRegression(max_iter=LR_MAX_ITER))\n",
        "])\n",
        "\n",
        "train_and_evaluate(pipeline, X_train_i, y_train_i, X_test, y_test, run_name, run)\n",
        "\n",
        "wandb.finish()\n",
        "\n",
        "print(\"Experiment tracking completed.\")"
      ],
      "metadata": {
        "id": "G1p7InTFY2sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare Models in W&B\n",
        "\n",
        "Once we have trained our models we can utilise W&B to compare them by heading to our Project and looking at the charts that are generated, W&B will compare different models across the charts that we specified for them during the model training process. It's important to identify what plots we want ahead of time to ensure that we can always compare them easily!\n",
        "\n",
        "![Compare ML Models in W&B](https://drive.google.com/uc?id=1WSKNK3rlwTr_e-mhVhjCNy-LcSBg3amw)"
      ],
      "metadata": {
        "id": "edQHXBDZLV7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetch and Run Inference using the Model from Model Registry\n",
        "\n",
        "Now that we have logged our models to the model registry, let's try loading it here and performing inference with it using the ONNX Runtime to verify that everything works as expected!"
      ],
      "metadata": {
        "id": "DmXLQnNY5Px-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "run = wandb.init()\n",
        "downloaded_model_path = run.use_model(name=\"YOUR MODEL NAME\")\n",
        "print(downloaded_model_path)"
      ],
      "metadata": {
        "id": "Np4oLngP22lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import onnxruntime as rt\n",
        "\n",
        "# First we must start a session.\n",
        "sess = rt.InferenceSession(downloaded_model_path)\n",
        "# The name of the input is saved as part of the .onnx file.\n",
        "# We are retreiving it because we will need it later.\n",
        "input_name = sess.get_inputs()[0].name\n",
        "print(f\"{input_name=}\")\n",
        "# This code will run the model on our behalf.\n",
        "query = \"I loved the product!\"\n",
        "_, probas = sess.run(None, {input_name: np.array([[query]])})\n",
        "print(probas[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZwjUxlj2g_4",
        "outputId": "cf4881cd-0fe4-4c7c-8028-bff5d76a518b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_name='text_input'\n",
            "{0: 0.15315383672714233, 1: 0.03383561223745346, 2: 0.813010573387146}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [OPTIONAL] Advanced Models for Sentiment Analysis\n",
        "\n",
        "For those interested in exploring more sophisticated approaches, this section introduces two advanced techniques: using BERT embeddings as a featurizer and leveraging Large Language Models (LLMs) for sentiment analysis.\n",
        "\n",
        "### 1. BERT Embeddings with Logistic Regression\n",
        "\n",
        "This approach uses BERT to create embeddings, which are then fed into a logistic regression classifier.\n",
        "\n",
        "```python\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "class TransformerFeaturizer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
        "        # TODO: Initialize the SentenceTransformer model\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        # TODO: Use the SentenceTransformer model to create embeddings for the input text\n",
        "        pass\n",
        "\n",
        "# Training and evaluation\n",
        "models_advanced = {}\n",
        "for n in TRAIN_SIZE_EVALS:\n",
        "    print(f\"Evaluating BERT+LR for training data size = {n}\")\n",
        "    X_train_i = X_train[:n]\n",
        "    Y_train_i = Y_train[:n]\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('featurizer', TransformerFeaturizer()),\n",
        "        ('classifier', LogisticRegression(max_iter=1000))\n",
        "    ])\n",
        "\n",
        "    # TODO: Fit the pipeline, make predictions, and calculate metrics\n",
        "    # Store results in models_advanced[n]\n",
        "\n",
        "    print(f\"Accuracy on test set: {models_advanced[n]['accuracy']}\")\n",
        "```\n",
        "\n",
        "### 2. LLM-based Sentiment Analysis\n",
        "\n",
        "This approach uses a Large Language Model for zero-shot and few-shot sentiment analysis.\n",
        "\n",
        "```python\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Initialize your LLM (replace with your preferred model)\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# Zero-shot prompting\n",
        "zero_shot_template = \"\"\"\n",
        "YOUR PROMPT\n",
        "\"\"\"\n",
        "zero_shot_prompt = PromptTemplate(input_variables=[\"review\"], template=zero_shot_template)\n",
        "zero_shot_chain = LLMChain(llm=llm, prompt=zero_shot_prompt)\n",
        "\n",
        "# TODO: Implement zero-shot sentiment analysis on a sample of drug reviews\n",
        "\n",
        "# Few-shot prompting\n",
        "few_shot_template = \"\"\"\n",
        "YOUR PROMPT\n",
        "\"\"\"\n",
        "few_shot_prompt = PromptTemplate(input_variables=[\"review\"], template=few_shot_template)\n",
        "few_shot_chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
        "\n",
        "# TODO: Implement few-shot sentiment analysis on a sample of drug reviews\n",
        "\n",
        "# TODO: Compare the performance of zero-shot and few-shot approaches\n",
        "```"
      ],
      "metadata": {
        "id": "0ebHN6ttzcVe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [OPTIONAL] Model Evaluation: Estimating Confidence Intervals with Bootstrap Sampling\n",
        "\n",
        "When evaluating machine learning models, it's crucial to understand not just the point estimates of performance metrics, but also the uncertainty around these estimates. Bootstrap sampling is a powerful technique that allows us to estimate confidence intervals for our model's performance metrics.\n",
        "\n",
        "## Why Bootstrap Sampling?\n",
        "\n",
        "1. **Quantify Uncertainty**: Bootstrap sampling helps us quantify the uncertainty in our model's performance metrics.\n",
        "2. **Robustness**: It provides a more robust estimate of model performance than a single point estimate.\n",
        "3. **No Distributional Assumptions**: Bootstrap sampling doesn't require assumptions about the underlying distribution of the data.\n",
        "\n",
        "## Implementing Bootstrap Sampling\n",
        "\n",
        "Here's a step-by-step guide to implement bootstrap sampling for estimating confidence intervals:\n",
        "\n",
        "1. **Generate Bootstrap Samples**:\n",
        "   Create N (e.g., 1000) bootstrap samples, each the same size as your original test set. Each sample is created by randomly selecting instances from the test set with replacement.\n",
        "\n",
        "2. **Calculate Metrics for Each Sample**:\n",
        "   For each bootstrap sample, calculate the performance metrics you're interested in (e.g., accuracy, F1-score).\n",
        "\n",
        "3. **Sort the Results**:\n",
        "   Sort the N values for each metric in ascending order.\n",
        "\n",
        "4. **Compute Confidence Intervals**:\n",
        "   The 95% confidence interval is given by the 2.5th and 97.5th percentiles of the sorted values."
      ],
      "metadata": {
        "id": "hl4SWY8ltr7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "def bootstrap_sample(X, y, n_samples):\n",
        "    # TODO: Implement bootstrap sampling\n",
        "    # Hint: Use np.random.randint to generate random indices\n",
        "    pass\n",
        "\n",
        "def bootstrap_confidence_interval(model, X_test, y_test, n_iterations=1000):\n",
        "    accuracies = []\n",
        "    f1_scores = []\n",
        "    n_samples = len(X_test)\n",
        "\n",
        "    for _ in tqdm(range(n_iterations)):\n",
        "        # TODO: Generate bootstrap sample\n",
        "        # TODO: Make predictions on bootstrap sample\n",
        "        # TODO: Calculate accuracy and F1-score\n",
        "        # TODO: Append results to accuracies and f1_scores lists\n",
        "        pass\n",
        "\n",
        "    # TODO: Calculate mean and confidence intervals for accuracy and F1-score\n",
        "    # Hint: Use np.percentile for confidence intervals\n",
        "\n",
        "    # TODO: Return results in a dictionary format\n",
        "\n",
        "# Usage\n",
        "# TODO: Call the bootstrap_confidence_interval function with your model and test data\n",
        "# TODO: Print the results"
      ],
      "metadata": {
        "id": "INgQ_7E4uH19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [OPTIOANL] Post-Training Tests on Model Behavior\n",
        "\n",
        "After training your sentiment analysis model, it's crucial to thoroughly test its behavior beyond just accuracy metrics. This section introduces three types of behavioral tests that will help you understand your model's strengths, weaknesses, and potential biases.\n",
        "\n",
        "## Invariance Tests\n",
        "\n",
        "Invariance tests check whether your model's output remains unchanged when irrelevant input features are modified.\n",
        "\n",
        "### Example: Name Invariance Test\n",
        "\n",
        "In sentiment analysis, a person's name mentioned in a review should not affect the sentiment prediction.\n",
        "\n",
        "**Test Setup:**\n",
        "1. Select a set of reviews from your test dataset.\n",
        "2. Create copies of these reviews, replacing any mentioned names with different names.\n",
        "3. Run both the original and modified reviews through your model.\n",
        "4. Compare the sentiment predictions.\n",
        "\n",
        "**Expected Outcome:** The sentiment predictions should remain the same for both original and name-modified reviews.\n",
        "\n",
        "## Directional Expectation Tests\n",
        "\n",
        "Directional Expectation Tests check if changes in input lead to expected changes in output.\n",
        "\n",
        "### Example: Intensifier Test\n",
        "\n",
        "Adding intensity-related words should increase the strength of the sentiment prediction.\n",
        "\n",
        "**Test Setup:**\n",
        "1. Select a set of positive and negative reviews from your test dataset.\n",
        "2. Create copies of these reviews, adding intensifiers like \"very\", \"extremely\", or \"incredibly\".\n",
        "3. Run both the original and modified reviews through your model.\n",
        "4. Compare the sentiment prediction probabilities.\n",
        "\n",
        "**Expected Outcome:** The sentiment prediction probability should increase in the direction of the original sentiment.\n",
        "\n",
        "## Minimum Functionality Tests\n",
        "\n",
        "Minimum Functionality Tests check if your model performs correctly on very simple or critical cases.\n",
        "\n",
        "### Example: Explicit Sentiment Words Test\n",
        "\n",
        "Reviews containing explicit sentiment words should be correctly classified.\n",
        "\n",
        "**Test Setup:**\n",
        "1. Create a list of reviews using explicit positive and negative sentiment words.\n",
        "2. Run these through your model.\n",
        "3. Check if the predictions match the expected sentiments.\n",
        "\n",
        "**Expected Outcome:** The model should correctly classify these simple, explicit sentiment expressions with high accuracy."
      ],
      "metadata": {
        "id": "oeBNGp6hlheA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import checklist\n",
        "from checklist.editor import Editor\n",
        "from checklist.test_types import MFT\n",
        "from checklist.pred_wrapper import PredictorWrapper\n",
        "\n",
        "editor = Editor()\n",
        "\n",
        "# TODO: Define variables for test data generation\n",
        "# Example:\n",
        "# positive_words = ['excellent', 'amazing', 'fantastic']\n",
        "# negative_words = ['terrible', 'awful', 'horrible']\n",
        "# neutral_words = ['okay', 'average', 'mediocre']\n",
        "# products = ['movie', 'book', 'restaurant', 'hotel']\n",
        "\n",
        "# TODO: Create templates for Invariance Tests\n",
        "# Example: Name Invariance Test\n",
        "# ret = editor.template('According to {name}, the {product} was {quality}.',\n",
        "#                       name=['John', 'Emma', 'Mohammed', 'Yuki', 'Maria'],\n",
        "#                       product=products,\n",
        "#                       quality=positive_words + negative_words + neutral_words,\n",
        "#                       labels='Sentiment')\n",
        "\n",
        "# TODO: Create templates for Directional Expectation Tests\n",
        "# Example: Intensifier Test\n",
        "# ret += editor.template('The {product} was {intensifier} {quality}.',\n",
        "#                        product=products,\n",
        "#                        intensifier=['', 'very', 'extremely'],\n",
        "#                        quality=positive_words + negative_words,\n",
        "#                        labels='Sentiment')\n",
        "\n",
        "# TODO: Create templates for Minimum Functionality Tests\n",
        "# Example: Explicit Sentiment Words Test\n",
        "# ret += editor.template('This {product} is {quality}.',\n",
        "#                        product=products,\n",
        "#                        quality=positive_words + negative_words,\n",
        "#                        labels='Sentiment')\n",
        "\n",
        "# Part 2: Test Configuration\n",
        "\n",
        "# TODO: Configure the MFT test\n",
        "# test = MFT(**ret, name='Sentiment Analysis Behavioral Tests')\n",
        "\n",
        "# Part 3: Test Run & Results summary\n",
        "\n",
        "# TODO: Implement a function to use your trained model for predictions\n",
        "def predict_sentiment(texts):\n",
        "    # Your code here to make predictions using your trained model\n",
        "    pass\n",
        "\n",
        "# TODO: Wrap your prediction function\n",
        "# wrapped_predictor = PredictorWrapper.wrap_predict(predict_sentiment)\n",
        "\n",
        "# TODO: Run the test and display results\n",
        "# test.run(wrapped_predictor)\n",
        "# test.summary()"
      ],
      "metadata": {
        "id": "x0Jm1KzIwS6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecting the Model to Productionize\n",
        "\n",
        "Now that you've trained, evaluated, and performed behavioral testing on your sentiment analysis models, it's time to select the best model for production deployment. This decision should be based on a comprehensive analysis of each model's performance, behavior, and suitability for the real-world application. For this project the full justification step is left as an optional task. We recommend you just pick a simple model that can be easily be deployed like the Logistic Regression model.\n",
        "\n",
        "## [OPTIONAL] Model Selection and Justification\n",
        "\n",
        "Example table of factors to consider:\n",
        "\n",
        "| Aspect | Logistic Regression | BERT | [Other Models] |\n",
        "|--------|---------------------|------|----------------|\n",
        "| Accuracy | | | |\n",
        "| F1 Score | | | |\n",
        "| Invariance Test | | | |\n",
        "| Directional Test | | | |\n",
        "| MF Test | | | |\n",
        "| Pros | | | |\n",
        "| Cons | | | |\n",
        "| Training Time | | | |\n",
        "| Inference Time | | | |\n",
        "| Explainability | | | |\n",
        "\n",
        "1. Review your models' performance, considering factors such as:\n",
        "   - Accuracy, F1 Score, Precision, Recall\n",
        "   - Results from Invariance, Directional Expectation, and Minimum Functionality Tests\n",
        "   - Training and inference time\n",
        "   - Model size and resource requirements\n",
        "   - Explainability and interpretability\n",
        "   - Robustness and potential biases\n",
        "\n",
        "2. Write a brief justification for your chosen model, addressing:\n",
        "   - Why this model is the best fit for the drug review sentiment analysis task\n",
        "   - How it balances performance, efficiency, and robustness\n",
        "   - Any potential challenges or limitations, and how you plan to address them\n",
        "   - How this model aligns with the business requirements and constraints\n",
        "\n",
        "3. Promote the selected model to production in Weights & Biases (W&B):\n",
        "   - Log into your W&B account\n",
        "   - Navigate to your project\n",
        "   - Find the run corresponding to your selected model\n",
        "   - Use the W&B UI to promote this model to `production` by changing the alias to it\n",
        "   - Provide any necessary metadata or tags"
      ],
      "metadata": {
        "id": "mSPZIMbLrI4X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SRQ41w05UE3h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}